{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import array\n",
    "import numpy as np                                        \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_bin = \"D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data\"\n",
    "file_path_cd = \"D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Individual CD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD_01_Manoj.xlsx\n",
      "CD_02_Bharti.xlsx\n",
      "CD_03_Rakesh.xlsx\n",
      "CD_04_Dilpreet.xlsx\n",
      "CD_05_Deepti.xlsx\n",
      "CD_06_Deepa.xlsx\n",
      "CD_07_Dilpreet_Manoj.xlsx\n",
      "CD_08_Ashwani_Bharti.xlsx\n",
      "CD_09_Deepti_Deepa.xlsx\n",
      "CD_10_Manoj.xlsx\n"
     ]
    }
   ],
   "source": [
    "feature = ''\n",
    "individual_cd = {}\n",
    "pathlist = Path(file_path_cd).glob('**/*.xlsx')\n",
    "for pathObj in pathlist:\n",
    "    path_in_str = str(pathObj)\n",
    "    print(path_in_str.split('\\\\')[-1])\n",
    "    cd_data = pd.read_excel(path_in_str, sheet_name='Sheet3')\n",
    "    cd_data.columns = np.arange(0,len(cd_data.columns))\n",
    "    cd_data = cd_data[[1,3,4,11,5]].dropna(thresh = 1)\n",
    "    cd_data[11] = cd_data[11].str.lower()\n",
    "    cd_data = cd_data[cd_data[11].str.contains(feature)]\n",
    "    cd_data.columns = ['Page_Number', '5k_Sample_Count', 'Abs_Val', 'Feature', 'Central_Sensor']\n",
    "    key = int(path_in_str.split('\\\\')[-1].split('_')[1])\n",
    "    \n",
    "    individual_cd['CD_' + str(key)] = []\n",
    "    individual_cd['CD_' + str(key)].append(cd_data)\n",
    "    \n",
    "#Appending names of associate bin file at index 1 of the lists \n",
    "pathlist = Path(file_path_bin).glob('**/*.bin')\n",
    "for pathObj in pathlist:\n",
    "    path_in_str = str(pathObj)\n",
    "    key  = 'CD_' + path_in_str.split('\\\\')[-1].split('_')[1]\n",
    "    for value in individual_cd:\n",
    "        if (value == key):\n",
    "            individual_cd[value].append(path_in_str.split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Bin files, processing and Storing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD_1 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_1_18.12.2015_18.10.17.bin\n",
      "700034000\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_2 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_2_18.12.2015_20.32.34.bin\n",
      "700025800\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_3 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_3_18.12.2015_22.54.51.bin\n",
      "700075000\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_4 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_4_19.12.2015_01.17.10.bin\n",
      "700034000\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_5 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_5_19.12.2015_03.39.27.bin\n",
      "700009400\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_6 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_6_19.12.2015_06.01.44.bin\n",
      "700083200\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_7 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_7_19.12.2015_08.24.01.bin\n",
      "700050400\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_8 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_8_19.12.2015_10.46.19.bin\n",
      "700107800\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n",
      "600 page processed\n",
      "700 page processed\n",
      "800 page processed\n",
      "CD_9 D:/MASS/14 inch IPIG ILI run data/IOCL_DELHI_PANIPAT_RUN_5_DEC_2015/Data/DATA_9_19.12.2015_13.08.37.bin\n",
      "700001200\n",
      "853\n",
      "100 page processed\n",
      "200 page processed\n",
      "300 page processed\n",
      "400 page processed\n",
      "500 page processed\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-87279394883a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdistance_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mvar1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mlister\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-6396be2dd173>\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mvar1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mvar1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma_for_filtering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvar1\u001b[0m \u001b[1;31m#, var2, var3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\env35\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\env35\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\env35\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    349\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m    350\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\env35\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     if (warn_on_dtype and dtypes_orig is not None and\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pig_run_name = file_path_bin.split(\"/\")[-2]\n",
    "sigma_for_filtering = 2\n",
    "distance_count = 5000\n",
    "primary_sensors_count = 84                                \n",
    "secondary_sensors_count = 72                              \n",
    "other_sensors_count = 8\n",
    "pri_skip = 1\n",
    "sec_skip = 1\n",
    "other_skip = 1\n",
    "last_primary_channel = primary_sensors_count*pri_skip\n",
    "last_secondary_channel = last_primary_channel + secondary_sensors_count*sec_skip\n",
    "last_other_channel = last_secondary_channel  + other_sensors_count*other_skip\n",
    "max_channels = last_other_channel\n",
    "primary_data = np.zeros((primary_sensors_count, distance_count), dtype = np.float)\n",
    "secondary_data = np.zeros((secondary_sensors_count, distance_count), dtype = np.float)\n",
    "other_data = np.zeros((other_sensors_count, distance_count), dtype = np.float)\n",
    "buffer = np.zeros((max_channels, distance_count), dtype = np.float)\n",
    "\n",
    "\n",
    "temp_list = pd.DataFrame()\n",
    "labelled_data = pd.DataFrame()\n",
    "dict_cd_data = {}\n",
    "dict_run_data = {}\n",
    "for k in individual_cd:\n",
    "    file_path = file_path_bin + '/' + individual_cd[k][1]\n",
    "    print(k, file_path)\n",
    "    sid = 25\n",
    "    lister = []\n",
    "    fid = open(file_path, 'rb')\n",
    "    fid.seek(0,0)\n",
    "    EOF = fid.seek(0,2)\n",
    "    print(EOF)\n",
    "    total_page_count = int(EOF/(5000*max_channels))\n",
    "    print(total_page_count)\n",
    "    num = 0\n",
    "    while (num < total_page_count):\n",
    "        fid.seek(num*(primary_sensors_count + secondary_sensors_count + other_sensors_count)*distance_count,0)\n",
    "        arr = array.array(\"b\")\n",
    "        arr.fromfile(fid, ((max_channels)*distance_count))\n",
    "        var1 = prepare_data(arr)\n",
    "        lister.append(var1)\n",
    "        num = num + 1\n",
    "        if(num%100==0): print(num, 'page processed')\n",
    "    fid.close() \n",
    "    dict_cd_data[k] = lister\n",
    "dict_run_data[pig_run_name] = dict_cd_data\n",
    "%store dict_run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_run_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(arr):\n",
    "    k =  0\n",
    "    for iota in range(0, distance_count):\n",
    "        for j in range(0, max_channels):\n",
    "            buffer[j,iota]=arr[k]\n",
    "            k=k+1\n",
    "    \n",
    "    p1 = 0     \n",
    "    for channel in range(0, last_primary_channel):\n",
    "        for samp in range(0, distance_count):\n",
    "            temp = buffer[channel,samp]\n",
    "            temp2 = 511\n",
    "            primary_data[p1, samp] = ((temp*4) + temp2)*5/2048\n",
    "        p1 = p1 + 1\n",
    "        \n",
    "#     p2 = 0     \n",
    "#     for channel in range(last_primary_channel, last_secondary_channel):\n",
    "#         for samp in range(0, distance_count):\n",
    "#             temp = buffer[channel,samp]\n",
    "#             temp2 = 511\n",
    "#             secondary_data[p2, samp] = ((temp*4) + temp2)*5/2048\n",
    "#         p2 = p2 + 1\n",
    "        \n",
    "    p3 = 0     \n",
    "#     for channel in range(last_secondary_channel, last_other_channel):\n",
    "#         for samp in range(0, distance_count):\n",
    "#             temp = buffer[channel,samp]\n",
    "# #             temp2 = 511\n",
    "#             other_data[p3, samp] = temp \n",
    "# #     ((temp*4) + temp2)*5/2048\n",
    "#         p3 = p3 + 1\n",
    "        \n",
    "    pri_parent = [primary_data]\n",
    "#     sec_parent = [secondary_data]\n",
    "#     other_parent = [other_data]\n",
    "\n",
    "    for value in range(0, len(pri_parent)):\n",
    "        pri_parent[value] = pd.DataFrame(pri_parent[value]).transpose().dropna()\n",
    "#     for value in range(0, len(sec_parent)):\n",
    "#         sec_parent[value] = pd.DataFrame(sec_parent[value]).transpose().dropna()\n",
    "#     for value in range(0, len(other_parent)):\n",
    "#         other_parent[value] = pd.DataFrame(other_parent[value]).transpose().dropna()\n",
    "\n",
    "    var1 = pri_parent[0].copy()\n",
    "#     var2 = sec_parent[0].copy()\n",
    "#     var3 = other_parent[0].copy()\n",
    "    #Plotting grayscale raw\n",
    "#     plot_grayscale(var1.transpose(), abs_folder_path, 'primary/raw/image_'+ str(page_number))\n",
    "#     plot_grayscale(var2.transpose(), abs_folder_path, 'secondary/raw/image_'+ str(page_number))\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    var1 = pd.DataFrame(scaler.fit_transform(var1))\n",
    "    var1 = pd.DataFrame(gaussian_filter(var1, sigma=sigma_for_filtering))\n",
    "    return var1 #, var2, var3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
